{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\001\\glasses\\nonsleepyCombination.avi\n",
      ".\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\001\\glasses\\sleepyCombination.avi\n",
      ".\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\001\\glasses\\slowBlinkWithNodding.avi\n",
      ".\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\001\\glasses\\yawning.avi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\001\\glasses'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".avi\" in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "        \n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop image and Label\n",
    "[HAAR Classifier](http://blog.topspeedsnail.com/archives/10511)\n",
    "- haarcascade_frontalface_default(想法: 直接用這個切出臉部的框框)\n",
    "- haarcascade_eye\n",
    "- problem: 多個人臉的問題防範\n",
    "- 用landmark下去圈，否則會不夠精準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#==================Detector\n",
    "face_haar = cv2.CascadeClassifier(\".\\Tool\\Detecter\\haarcascade_frontalface_default.xml\")\n",
    "eye_haar = cv2.CascadeClassifier(\".\\Tool\\Detecter\\haarcascade_eye.xml\")\n",
    "mouth_haar = cv2.CascadeClassifier(\".\\Tool\\Detecter\\haarcascade_mcs_mouth.xml\")\n",
    "nose_haar = cv2.CascadeClassifier(\".\\Tool\\Detecter\\haarcascade_mcs_nose.xml\")\n",
    "#==================\n",
    "\n",
    "filename = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\005\\glasses\\yawning.avi'\n",
    "cap = cv2.VideoCapture(filename)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    #print(type(frame))\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #===========Detect global part and local part by haar\n",
    "    faces = face_haar.detectMultiScale(gray_img, 1.3, 5)\n",
    "    #faces = face_haar.detectMultiScale(gray_img,scaleFactor=1.15,minNeighbors=5,minSize=(5,5),flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    for face_x,face_y,face_w,face_h in faces:\n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x+face_w, face_y+face_h), (0,255,0), 2)\n",
    "            # 眼长在脸上\n",
    "        roi_gray_img = gray_img[face_y:face_y+face_h, face_x:face_x+face_w]\n",
    "        roi_img = frame[face_y:face_y+face_h, face_x:face_x+face_w]\n",
    "\n",
    "        eyes = eye_haar.detectMultiScale(roi_gray_img, 1.3, 5)\n",
    "        for eye_x,eye_y,eye_w,eye_h in eyes:\n",
    "            cv2.rectangle(roi_img, (eye_x,eye_y), (eye_x+eye_w, eye_y+eye_h), (255,0,0), 2)\n",
    "\n",
    "        noses = nose_haar.detectMultiScale(roi_gray_img, 1.7, 5)\n",
    "        for nose_x,nose_y,nose_w,nose_h in noses:\n",
    "            cv2.rectangle(roi_img, (nose_x,nose_y), (nose_x+nose_w, nose_y+nose_h), (255,0,255), 2)\n",
    "\n",
    "        mouthes = mouth_haar.detectMultiScale(roi_gray_img, 1.5, 7)\n",
    "        for mouth_x,mouth_y,mouth_w,mouth_h in mouthes:\n",
    "            cv2.rectangle(roi_img, (mouth_x,mouth_y), (mouth_x+mouth_w, mouth_y+mouth_h), (255,255,0), 2)\n",
    "                \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### landmark\n",
    "\n",
    "- [reference](https://github.com/italojs/facial-landmarks-recognition-)\n",
    "- [find max value of the same index](https://stackoverflow.com/questions/39748916/find-maximum-value-and-index-in-a-python-list)<br>\n",
    "解釋了為什麼要再用CNN，因為landmark無法偵測得很精準。\n",
    "1~27: 臉部輪廓\n",
    "28~36:鼻子\n",
    "37~42:左眼\n",
    "43~48:右眼\n",
    "49~68:嘴巴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "filename = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\001\\glasses\\yawning.avi'\n",
    "cap = cv2.VideoCapture(filename)\n",
    "\n",
    "ImageDataList = []\n",
    "\n",
    " \n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # load the input image and convert it to grayscale\n",
    "    ret, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        #count = 0\n",
    "        face_x = face_y = 0\n",
    "        \n",
    "        #face_y = face_y-1\n",
    "        #face_x = face_x+1\n",
    "        #print(str(face_x)+\" \"+str(face_y))\n",
    "        '''\n",
    "        for (x, y) in shape:\n",
    "            #count = count+1\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "            #if():\n",
    "            \n",
    "            #if(count>=49 and count<=69):\n",
    "                #cv2.putText(image,str(count), (x+2 , y+2 ), cv2.FONT_HERSHEY_COMPLEX,0.5, (0, 255, 255))\n",
    "        '''\n",
    "        #print(shape[0:3][0])\n",
    "        #print(shape[1:10])\n",
    "        #index, value = max(shape[1:10], key=lambda item: item[1])\n",
    "       \n",
    "        #max_value = max(shape[1:10], key=itemgetter(1))[0]\n",
    "        #print(value)\n",
    "        \n",
    "        #print(max(shape[0:28], key=itemgetter(0))[0])#find max value of x \n",
    "        #print(max(shape[0:28], key=itemgetter(1))[1])#find max value of y \n",
    "        \n",
    "        #==================================================Detect local part and global part\n",
    "        face_max_x = max(shape[0:27], key=itemgetter(0))[0]\n",
    "        face_min_x = min(shape[0:27], key=itemgetter(0))[0]\n",
    "        face_max_y = max(shape[0:27], key=itemgetter(1))[1]\n",
    "        face_min_y = min(shape[0:27], key=itemgetter(1))[1]\n",
    "        face_image = image[face_min_y:face_max_y,face_min_x:face_max_x]\n",
    "        cv2.rectangle(image,(face_min_x,face_min_y),(face_max_x,face_max_y),(0, 255, 255),2)\n",
    "        \n",
    "        nose_max_x = max(shape[27:36], key=itemgetter(0))[0]\n",
    "        nose_min_x = min(shape[27:36], key=itemgetter(0))[0]\n",
    "        nose_max_y = max(shape[27:36], key=itemgetter(1))[1]\n",
    "        nose_min_y = min(shape[27:36], key=itemgetter(1))[1]\n",
    "        nose_image = image[nose_min_y:nose_max_y,nose_min_x:nose_max_x]\n",
    "        cv2.rectangle(image,(nose_min_x,nose_min_y),(nose_max_x,nose_max_y),(255, 255, 0),2)\n",
    "        \n",
    "        lefteye_max_x = max(shape[36:42], key=itemgetter(0))[0]\n",
    "        lefteye_min_x = min(shape[36:42], key=itemgetter(0))[0]\n",
    "        lefteye_max_y = max(shape[36:42], key=itemgetter(1))[1]\n",
    "        lefteye_min_y = min(shape[36:42], key=itemgetter(1))[1]\n",
    "        lefteye_image = image[lefteye_min_y:lefteye_max_y,lefteye_min_x:lefteye_max_x]\n",
    "        cv2.rectangle(image,(lefteye_min_x,lefteye_min_y),(lefteye_max_x,lefteye_max_y),(255, 0, 0),2)\n",
    "        \n",
    "        righteye_max_x = max(shape[42:48], key=itemgetter(0))[0]\n",
    "        righteye_min_x = min(shape[42:48], key=itemgetter(0))[0]\n",
    "        righteye_max_y = max(shape[42:48], key=itemgetter(1))[1]\n",
    "        righteye_min_y = min(shape[42:48], key=itemgetter(1))[1]\n",
    "        righteye_image = image[righteye_min_y:righteye_max_y,righteye_min_x:righteye_max_x]\n",
    "        cv2.rectangle(image,(righteye_min_x,righteye_min_y),(righteye_max_x,righteye_max_y),(255, 255, 255),2)\n",
    "        \n",
    "        mouth_max_x = max(shape[48:], key=itemgetter(0))[0]\n",
    "        mouth_min_x = min(shape[48:], key=itemgetter(0))[0]\n",
    "        mouth_max_y = max(shape[48:], key=itemgetter(1))[1]\n",
    "        mouth_min_y = min(shape[48:], key=itemgetter(1))[1]\n",
    "        mouth_image = image[mouth_min_y:mouth_max_y,mouth_min_x:mouth_max_x]\n",
    "        cv2.rectangle(image,(mouth_min_x,mouth_min_y),(mouth_max_x,mouth_max_y),(255, 0, 255),2)\n",
    "        #==================================================\n",
    "        \n",
    "        '''\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (255, 0, 0), -1)\n",
    "        '''    \n",
    "        \n",
    "\n",
    "    \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    cv2.imshow(\"face_image\", face_image)\n",
    "    cv2.imshow(\"nose_image\", nose_image)\n",
    "    cv2.imshow(\"lefteye_image\", lefteye_image)\n",
    "    cv2.imshow(\"righteye_image\", righteye_image)\n",
    "    cv2.imshow(\"mouth_image\", mouth_image)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1850,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#注意開頭是數字的資料夾或檔案\n",
    "labelfile = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\001\\glasses\\\\001_yawning_drowsiness.txt'\n",
    "LabelList = []\n",
    "\n",
    "inputfile = open(labelfile, 'r').read()\n",
    "\n",
    "\n",
    "LabelList = list(map(int, inputfile))\n",
    "Labelarray = np.array(LabelList)\n",
    "Labelarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
