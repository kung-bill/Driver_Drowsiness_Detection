{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '~/Document/NTHU_dataset/Training_Evaluation_Dataset/Evaluation Dataset'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".mp4\" in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "        \n",
    "for f in files:\n",
    "    print(f)\n",
    "np.array(files).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-351f42516392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m61\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(files[i][57:60])\n",
    "    print(files[i][61:-4])\n",
    "    print(files[i][57:-4])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "\n",
    "eyes_width = 60\n",
    "eyes_height = 33\n",
    "mouth_width = 50\n",
    "mouth_height = 33\n",
    "face_width = 66\n",
    "face_height = 85\n",
    "num_classes = 2\n",
    "channel = 1\n",
    "\n",
    "eyes_width2 = 45\n",
    "eyes_height2 = 25\n",
    "mouth_width2 = 35\n",
    "mouth_height2 = 25\n",
    "face_width2 = 50\n",
    "face_height2 = 64\n",
    "\n",
    "\n",
    "def CreateFolder(name):\n",
    "    try:\n",
    "        # creating a folder named data \n",
    "        if not os.path.exists(name):\n",
    "            os.makedirs(name)\n",
    "        # if not created then raise error \n",
    "    except OSError: \n",
    "        print ('Error: Creating directory of data')            \n",
    "#==============================================================\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "for filename in files:\n",
    "    \n",
    "    #==========================\n",
    "    f = open('Testingdroplist.txt','a')\n",
    "    f.write(filename+\"\\n\")\n",
    "    f.close()\n",
    "    #==========================\n",
    "    # img = cv2.imread(\"me.jpg\")\n",
    "    \n",
    "    #filename = '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Training Dataset\\\\001\\\\glasses\\\\yawning.avi'\n",
    "\n",
    "    print(filename)\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    #================================================================ create new folder\n",
    "\n",
    "    DefaultPath = '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Testing Image\\\\'+filename[57:-4]+\"\\\\\"\n",
    "    CreateFolder(DefaultPath+\"face\")\n",
    "    CreateFolder(DefaultPath+\"eyes\")\n",
    "    CreateFolder(DefaultPath+\"mouth\")\n",
    "    #================================================================\n",
    "    Face_ImageDataList = []\n",
    "\n",
    "    currentframe = 0\n",
    "    missing_frame = 0\n",
    "    DropList = []\n",
    "\n",
    "    eyes_w = eyes_width\n",
    "    eyes_h = eyes_height\n",
    "    face_w = face_width\n",
    "    face_h = face_height\n",
    "    mouth_w = mouth_width\n",
    "    mouth_h = mouth_height\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(length)\n",
    "    x,y,w,h = 0,0,0,0\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        \n",
    "        currentframe += 1\n",
    "        # load the input image and convert it to grayscale\n",
    "        ret, image = cap.read()\n",
    "        if (not ret):\n",
    "          break\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "\n",
    "        \n",
    "        #3 frame sample once\n",
    "       # if(currentframe%3!=0):\n",
    "         #   continue\n",
    "        \n",
    "        #if(currentframe<2200):\n",
    "        #    continue\n",
    "        \n",
    "\n",
    "        height,width = image.shape[:2]\n",
    "        #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #image = cv2.resize(image,(width//2,height//2),interpolation=cv2.INTER_CUBIC)\n",
    "        #print(image.shape[:2])\n",
    "        faces = detector.detect_faces(image)\n",
    "        #print(np.array(faces).shape[0])\n",
    "        \n",
    "        if(np.array(faces).shape[0] > 0):\n",
    "            face = faces[0]\n",
    "            x,y,w,h = face['box']\n",
    "            \n",
    "            face_image = image[max(0,y):max(0,y+h),max(0,x):max(0,x+w)]\n",
    "            #print(face_image.shape)\n",
    "            #print(face_image.shape)\n",
    "            #print(image[x:x+w,y:y+h])\n",
    "            #cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            face_image1 = cv2.resize(face_image,(face_w,face_h),interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(DefaultPath + \"face\\\\frame_MiddleALL\" + str(currentframe) + '.jpg',face_image1)\n",
    "            \n",
    "           # face_image2 = cv2.resize(face_image,(face_width2,face_height2),interpolation=cv2.INTER_AREA)\n",
    "           # cv2.imwrite(DefaultPath + \"face\\\\frame_Small\" + str(currentframe) + '.jpg',face_image2) \n",
    "\n",
    "\n",
    "            eyes_image = image[max(0,face['keypoints']['left_eye'][1]-int(h*0.2)):max(0,face['keypoints']['right_eye'][1]+int(h*0.2))\n",
    "                                ,max(0,face['keypoints']['left_eye'][0]-int(w*0.2)):max(0,face['keypoints']['right_eye'][0]+int(w*0.2))]\n",
    "            \n",
    "            #cv2.rectangle(image, (face['keypoints']['left_eye'][0]-int(w*0.2), face['keypoints']['left_eye'][1]-int(h*0.2)),\n",
    "            #              (face['keypoints']['right_eye'][0]+int(w*0.2), face['keypoints']['right_eye'][1]+int(h*0.2)),(0, 255, 0),2)\n",
    "            eyes_image1 = cv2.resize(eyes_image,(eyes_w,eyes_h),interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(DefaultPath + \"eyes\\\\frame_MiddleALL\" + str(currentframe) + '.jpg',eyes_image1) \n",
    "            \n",
    "           # eyes_image2 = cv2.resize(eyes_image,(eyes_width2,eyes_height2),interpolation=cv2.INTER_AREA)\n",
    "           # cv2.imwrite(DefaultPath + \"eyes\\\\frame_Small\" + str(currentframe) + '.jpg',eyes_image2) \n",
    "\n",
    "\n",
    "            mouth_image = image[max(0,face['keypoints']['mouth_left'][1]-int(h*0.2)):max(0,face['keypoints']['mouth_right'][1]+int(h*0.2))\n",
    "                               ,max(0,face['keypoints']['mouth_left'][0]-int(w*0.2)):max(0,face['keypoints']['mouth_right'][0]+int(w*0.2))]\n",
    "            #cv2.rectangle(image, (face['keypoints']['mouth_left'][0]-int(w*0.2), face['keypoints']['mouth_left'][1]-int(h*0.2)),\n",
    "            #              (face['keypoints']['mouth_right'][0]+int(w*0.2), face['keypoints']['mouth_right'][1]+int(h*0.2)),(0, 255, 0),2)\n",
    "            mouth_image1 = cv2.resize(mouth_image,(mouth_w,mouth_h),interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(DefaultPath + \"mouth\\\\frame_MiddleALL\" + str(currentframe) + '.jpg',mouth_image1) \n",
    "            \n",
    "           # mouth_image2 = cv2.resize(mouth_image,(mouth_width2,mouth_height2),interpolation=cv2.INTER_AREA)\n",
    "           # cv2.imwrite(DefaultPath + \"mouth\\\\frame_Small\" + str(currentframe) + '.jpg',mouth_image2) \n",
    "\n",
    "\n",
    "\n",
    "            #cv2.rectangle(image, (face['keypoints']['left_eye'][0], face['keypoints']['left_eye'][1]), 2, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "            #cv2.circle(image, (face['keypoints']['left_eye'][0], face['keypoints']['left_eye'][1]), 2, (0, 255, 0), -1)\n",
    "            #cv2.circle(image, (face['keypoints']['right_eye'][0], face['keypoints']['right_eye'][1]), 2, (0, 255, 0), -1)\n",
    "            #cv2.circle(image, (face['keypoints']['nose'][0], face['keypoints']['nose'][1]), 2, (0, 255, 0), -1)\n",
    "            #cv2.circle(image, (face['keypoints']['mouth_left'][0], face['keypoints']['mouth_left'][1]), 2, (0, 255, 0), -1)\n",
    "            #cv2.circle(image, (face['keypoints']['mouth_right'][0], face['keypoints']['mouth_right'][1]), 2, (0, 255, 0), -1)\n",
    "            if(currentframe%100==0):        \n",
    "                name = './data/frame' + str(currentframe) + '.jpg'\n",
    "                print ('Creating...' + name) \n",
    "        elif (missing_frame<60 and (not((x == 0) or (y == 0) or (w == 0) or (h == 0) ))):\n",
    "            print ('missing using last frame') \n",
    "            missing_frame = missing_frame + 1        \n",
    "\n",
    "            face_image = image[max(0,y):max(0,y+h),max(0,x):max(0,x+w)]\n",
    "            \n",
    "            face_image1 = cv2.resize(face_image,(face_w,face_h),interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(DefaultPath + \"face\\\\frame_MiddleALL\" + str(currentframe) + '.jpg',face_image1)\n",
    "            \n",
    "           # face_image2 = cv2.resize(face_image,(face_width2,face_height2),interpolation=cv2.INTER_AREA)\n",
    "          #  cv2.imwrite(DefaultPath + \"face\\\\frame_Small\" + str(currentframe) + '.jpg',face_image2) \n",
    "\n",
    "\n",
    "            eyes_image = image[max(0,face['keypoints']['left_eye'][1]-int(h*0.2)):max(0,face['keypoints']['right_eye'][1]+int(h*0.2))\n",
    "                                ,max(0,face['keypoints']['left_eye'][0]-int(w*0.2)):max(0,face['keypoints']['right_eye'][0]+int(w*0.2))]\n",
    "            \n",
    "            #cv2.rectangle(image, (face['keypoints']['left_eye'][0]-int(w*0.2), face['keypoints']['left_eye'][1]-int(h*0.2)),\n",
    "            #              (face['keypoints']['right_eye'][0]+int(w*0.2), face['keypoints']['right_eye'][1]+int(h*0.2)),(0, 255, 0),2)\n",
    "            eyes_image1 = cv2.resize(eyes_image,(eyes_w,eyes_h),interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(DefaultPath + \"eyes\\\\frame_MiddleALL\" + str(currentframe) + '.jpg',eyes_image1) \n",
    "            \n",
    "           # eyes_image2 = cv2.resize(eyes_image,(eyes_width2,eyes_height2),interpolation=cv2.INTER_AREA)\n",
    "          #  cv2.imwrite(DefaultPath + \"eyes\\\\frame_Small\" + str(currentframe) + '.jpg',eyes_image2) \n",
    "\n",
    "\n",
    "            mouth_image = image[max(0,face['keypoints']['mouth_left'][1]-int(h*0.2)):max(0,face['keypoints']['mouth_right'][1]+int(h*0.2))\n",
    "                               ,max(0,face['keypoints']['mouth_left'][0]-int(w*0.2)):max(0,face['keypoints']['mouth_right'][0]+int(w*0.2))]\n",
    "            #cv2.rectangle(image, (face['keypoints']['mouth_left'][0]-int(w*0.2), face['keypoints']['mouth_left'][1]-int(h*0.2)),\n",
    "            #              (face['keypoints']['mouth_right'][0]+int(w*0.2), face['keypoints']['mouth_right'][1]+int(h*0.2)),(0, 255, 0),2)\n",
    "            mouth_image1 = cv2.resize(mouth_image,(mouth_w,mouth_h),interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(DefaultPath + \"mouth\\\\frame_MiddleALL\" + str(currentframe) + '.jpg',mouth_image1) \n",
    "            \n",
    "           # mouth_image2 = cv2.resize(mouth_image,(mouth_width2,mouth_height2),interpolation=cv2.INTER_AREA)\n",
    "           # cv2.imwrite(DefaultPath + \"mouth\\\\frame_Small\" + str(currentframe) + '.jpg',mouth_image2) \n",
    "            \n",
    "            #if(currentframe%100==0):\n",
    "            name = './data/frame' + str(currentframe) + '.jpg'\n",
    "            print ('missing using last frame:  '+ 'Creating...' + name) \n",
    "\n",
    "        else:\n",
    "            name = './data/frame' + str(currentframe) + '.jpg'\n",
    "            f = open('droplist.txt','a')\n",
    "            f.write(name+\"\\n\")\n",
    "            f.close()\n",
    "            DropList.append(currentframe)\n",
    "            print(\"drop\")\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        cv2.imshow('img',image)\n",
    "\n",
    "        #print(\"FPS: \", 1.0 / (time.time() - start_time))\n",
    "\n",
    "        k = cv2.waitKey(5) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "        '''\n",
    "    \n",
    "    print(\"total_frame:\" +str(length)+\" missing frame\"+ str(np.array(DropList).shape[0])+\" total frame2:\"+ str(currentframe))\n",
    "    print(DropList)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './MultiTask_Model_0820Best.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b57940bdbcc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./MultiTask_Model_0820Best.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./MultiTask_Model_0820Best.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './MultiTask_Model_0820Best.json'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.model_from_json(open('./MultiTask_Model_0820Best.json').read())\n",
    "model.load_weights('./MultiTask_Model_0820Best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Testing Image'\n",
    "\n",
    "AllImageFolder = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        \n",
    "        #print(directory)\n",
    "        path = str(os.path.join(r, file))\n",
    "        \n",
    "        if('eyes' in path):\n",
    "            AllImageFolder.append(os.path.join(r, file))\n",
    "        \n",
    "#for f in AllImageFolder:\n",
    "#    print(f)\n",
    "np.array(AllImageFolder).shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Testing Image'\n",
    "\n",
    "AllImageFolder = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for directory in d:\n",
    "        if (\"mix\" in directory):\n",
    "            #print(directory)\n",
    "            AllImageFolder.append(os.path.join(r, directory))\n",
    "        \n",
    "for d in AllImageFolder:\n",
    "    print(d)\n",
    "    \n",
    "#llImageFolder = AllImageFolder[2:]\n",
    "np.array(AllImageFolder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset'\n",
    "\n",
    "AllLabelFile = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"head.txt\" in file :\n",
    "            AllLabelFile.append(os.path.join(r, file))\n",
    "        \n",
    "for f in AllLabelFile:\n",
    "    print(f)\n",
    "    \n",
    "#AllLabelFile = AllLabelFile [2:]\n",
    "np.array(AllLabelFile).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 167208\n",
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from math import ceil\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LoadImageandLabel(batch_size,AllVideoImageFolder,AllLabelFile):\n",
    "    #print(Originalpath)\n",
    "    count=0\n",
    "    \n",
    "    while True:\n",
    "        LabelFileindex = 0\n",
    "        for Originalpath in AllVideoImageFolder:\n",
    "            labelPath = AllLabelFile[LabelFileindex]\n",
    "            LabelFileindex = LabelFileindex + 1\n",
    "\n",
    "            Face_ImageDataList = []\n",
    "            Eyes_ImageDataList = []\n",
    "            Mouth_ImageDataList = []\n",
    "            #=====load all label in a video\n",
    "            LabelList = []\n",
    "            TempLabelList = []\n",
    "            inputfile = open(labelPath, 'r').read()\n",
    "            TempLabelList = list(map(int, inputfile))\n",
    "\n",
    "            #=========================\n",
    "\n",
    "            TEMP_ImageDataList = []\n",
    "\n",
    "            path = Originalpath+\"\\\\face\"\n",
    "            \n",
    "\n",
    "            #=====find all files in path=======    \n",
    "            Facefiles = []\n",
    "            Eyefiles = []\n",
    "            Mouthfiles = []\n",
    "            # r=root, d=directories, f = files\n",
    "            for r, d, f in os.walk(path):\n",
    "                for file in f:\n",
    "                    if \".jpg\" in file:\n",
    "                        temp = os.path.join(r, file)\n",
    "                        Facefiles.append(temp)\n",
    "                        \n",
    "                        #Eyefiles.append(temp.replace(\"face\", \"eyes\"))\n",
    "                        #Mouthfiles.append(temp.replace(\"face\", \"mouth\"))\n",
    "\n",
    "\n",
    "            Facefiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            #Eyefiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            #Mouthfiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            \n",
    "            #Mouthfiles=Mouthfiles[:-2]\n",
    "            #Eyefiles=Eyefiles[:-2]\n",
    "            Facefiles=Facefiles[:-2]\n",
    "            #print(len(Mouthfiles))\n",
    "            #print(len(TempLabelList))\n",
    "            \n",
    "            for FileIndex in range(len(Facefiles)):\n",
    "                #======================load label\n",
    "\n",
    "                index = Facefiles[FileIndex].find('frame')\n",
    "                framenumber =int(Facefiles[FileIndex][index+5:-4]) \n",
    "                \n",
    "                #print(framenumber)\n",
    "\n",
    "                #if(judgeflag == 0 and TempLabelList[framenumber-1] == 1):\n",
    "                #    judgeflag = 1\n",
    "                    #print(framenumber-1)\n",
    "\n",
    "                #Labelarray = np.array(LabelList)\n",
    "                #print(len(TempLabelList))\n",
    "                #print(framenumber-1)\n",
    "                Labelarray = to_categorical(TempLabelList[framenumber-1], num_classes=3)\n",
    "                LabelList.append(Labelarray)\n",
    "                #print(LabelList)\n",
    "\n",
    "                    #Labelarray = np.array(LabelList)\n",
    "                    #Labelarray = to_categorical(Labelarray, num_classes=2)\n",
    "\n",
    "                #================================\n",
    "                ImgGray = cv2.imread(Facefiles[FileIndex],0)\n",
    "                #ImgRGB = cv2.merge((ImgGray,ImgGray,ImgGray))# this line make gray image to RGB\n",
    "                #TEMP_ImageDataList.append(ImgRGB)  \n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                #print(ImgGray.shape)\n",
    "                Face_ImageDataList.append(ImgGray)\n",
    "                #print(np.array(Face_ImageDataList).shape)\n",
    "                '''\n",
    "                ImgGray = cv2.imread(Mouthfiles[FileIndex],0)\n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                Mouth_ImageDataList.append(ImgGray)\n",
    "\n",
    "\n",
    "                ImgGray = cv2.imread(Eyefiles[FileIndex],0)\n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                Eyes_ImageDataList.append(ImgGray)\n",
    "                '''\n",
    "                 #====================================\n",
    "               \n",
    "                count = count +1\n",
    "                if count>=batch_size:\n",
    "\n",
    "                        yield ([np.array(Face_ImageDataList)],np.array(LabelList))\n",
    "                        count=0\n",
    "                        Face_ImageDataList = []\n",
    "                        Eyes_ImageDataList = []\n",
    "                        Mouth_ImageDataList = []\n",
    "                        LabelList = []\n",
    "\n",
    "                        \n",
    "#                   \n",
    "result= model.evaluate_generator(LoadImageandLabel(batch_size,AllImageFolder,AllLabelFile), steps=ceil(num_samples / batch_size),workers=5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.model_from_json(open('./MouthModelNEW.json').read())\n",
    "model.load_weights('./MouthModelNEW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Testing Image'\n",
    "\n",
    "AllImageFolder = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for directory in d:\n",
    "        if (\"mix\" in directory):\n",
    "            #print(directory)\n",
    "            AllImageFolder.append(os.path.join(r, directory))\n",
    "        \n",
    "for d in AllImageFolder:\n",
    "    print(d)\n",
    "    \n",
    "#llImageFolder = AllImageFolder[2:]\n",
    "np.array(AllImageFolder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset'\n",
    "\n",
    "AllLabelFile = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"mouth.txt\" in file :\n",
    "            AllLabelFile.append(os.path.join(r, file))\n",
    "        \n",
    "for f in AllLabelFile:\n",
    "    print(f)\n",
    "    \n",
    "#AllLabelFile = AllLabelFile [2:]\n",
    "np.array(AllLabelFile).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 167208\n",
    "batch_size = 250\n",
    "\n",
    "eyes_width = 45\n",
    "eyes_height = 25\n",
    "mouth_width = 35\n",
    "mouth_height = 25\n",
    "face_width = 50\n",
    "face_height = 64\n",
    "num_classes = 3\n",
    "channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from math import ceil\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LoadImageandLabel(batch_size,AllVideoImageFolder,AllLabelFile):\n",
    "    #print(Originalpath)\n",
    "    count=0\n",
    "    \n",
    "    while True:\n",
    "        LabelFileindex = 0\n",
    "        for Originalpath in AllVideoImageFolder:\n",
    "            labelPath = AllLabelFile[LabelFileindex]\n",
    "            LabelFileindex = LabelFileindex + 1\n",
    "\n",
    "            Face_ImageDataList = []\n",
    "            Eyes_ImageDataList = []\n",
    "            Mouth_ImageDataList = []\n",
    "            #=====load all label in a video\n",
    "            LabelList = []\n",
    "            TempLabelList = []\n",
    "            inputfile = open(labelPath, 'r').read()\n",
    "            TempLabelList = list(map(int, inputfile))\n",
    "\n",
    "            #=========================\n",
    "\n",
    "            TEMP_ImageDataList = []\n",
    "\n",
    "            path = Originalpath+\"\\\\face\"\n",
    "            \n",
    "\n",
    "            #=====find all files in path=======    \n",
    "            Facefiles = []\n",
    "            Eyefiles = []\n",
    "            Mouthfiles = []\n",
    "            # r=root, d=directories, f = files\n",
    "            for r, d, f in os.walk(path):\n",
    "                for file in f:\n",
    "                    if \".jpg\" in file:\n",
    "                        temp = os.path.join(r, file)\n",
    "                        Facefiles.append(temp)\n",
    "                        \n",
    "                        #Eyefiles.append(temp.replace(\"face\", \"eyes\"))\n",
    "                        #Mouthfiles.append(temp.replace(\"face\", \"mouth\"))\n",
    "\n",
    "            \n",
    "            Facefiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            #Eyefiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            #Mouthfiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            \n",
    "            #Mouthfiles=Mouthfiles[:-2]\n",
    "            #Eyefiles=Eyefiles[:-2]\n",
    "            Facefiles=Facefiles[:-2]\n",
    "            '''\n",
    "            print(len(Facefiles))\n",
    "            print(len(TempLabelList))\n",
    "            '''\n",
    "            for FileIndex in range(len(Facefiles)):\n",
    "                #======================load label\n",
    "\n",
    "                index = Facefiles[FileIndex].find('frame')\n",
    "                framenumber =int(Facefiles[FileIndex][index+5:-4]) \n",
    "                \n",
    "                #print(framenumber)\n",
    "\n",
    "                #if(judgeflag == 0 and TempLabelList[framenumber-1] == 1):\n",
    "                #    judgeflag = 1\n",
    "                    #print(framenumber-1)\n",
    "\n",
    "                #Labelarray = np.array(LabelList)\n",
    "                #print(len(TempLabelList))\n",
    "                #print(framenumber-1)\n",
    "                Labelarray = to_categorical(TempLabelList[framenumber-1], num_classes=3)\n",
    "                LabelList.append(Labelarray)\n",
    "                #print(LabelList)\n",
    "\n",
    "                    #Labelarray = np.array(LabelList)\n",
    "                    #Labelarray = to_categorical(Labelarray, num_classes=2)\n",
    "\n",
    "                #================================\n",
    "                ImgGray = cv2.imread(Facefiles[FileIndex],0)\n",
    "                #ImgRGB = cv2.merge((ImgGray,ImgGray,ImgGray))# this line make gray image to RGB\n",
    "                #TEMP_ImageDataList.append(ImgRGB)  \n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                #print(ImgGray.shape)\n",
    "                Face_ImageDataList.append(ImgGray)\n",
    "                #print(np.array(Face_ImageDataList).shape)\n",
    "                '''\n",
    "                ImgGray = cv2.imread(Mouthfiles[FileIndex],0)\n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                Mouth_ImageDataList.append(ImgGray)\n",
    "\n",
    "\n",
    "                ImgGray = cv2.imread(Eyefiles[FileIndex],0)\n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                Eyes_ImageDataList.append(ImgGray)\n",
    "                '''\n",
    "                 #====================================\n",
    "               \n",
    "                count = count +1\n",
    "                if count>=batch_size:\n",
    "\n",
    "                        yield ([np.array(Face_ImageDataList)],np.array(LabelList))\n",
    "                        count=0\n",
    "                        Face_ImageDataList = []\n",
    "                        Eyes_ImageDataList = []\n",
    "                        Mouth_ImageDataList = []\n",
    "                        LabelList = []\n",
    "                        \n",
    "#                   \n",
    "result= model.evaluate_generator(LoadImageandLabel(batch_size,AllImageFolder,AllLabelFile), steps=ceil(num_samples / batch_size),workers=5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.model_from_json(open('./EyeModelNEW.json').read())\n",
    "model.load_weights('./EyeModelNEW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Testing Image'\n",
    "\n",
    "AllImageFolder = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for directory in d:\n",
    "        if (\"mix\" in directory):\n",
    "            #print(directory)\n",
    "            AllImageFolder.append(os.path.join(r, directory))\n",
    "        \n",
    "for d in AllImageFolder:\n",
    "    print(d)\n",
    "    \n",
    "#llImageFolder = AllImageFolder[2:]\n",
    "np.array(AllImageFolder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset'\n",
    "\n",
    "AllLabelFile = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"eye.txt\" in file :\n",
    "            AllLabelFile.append(os.path.join(r, file))\n",
    "        \n",
    "for f in AllLabelFile:\n",
    "    print(f)\n",
    "    \n",
    "#AllLabelFile = AllLabelFile [2:]\n",
    "np.array(AllLabelFile).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 167208\n",
    "batch_size = 250\n",
    "\n",
    "eyes_width = 45\n",
    "eyes_height = 25\n",
    "mouth_width = 35\n",
    "mouth_height = 25\n",
    "face_width = 50\n",
    "face_height = 64\n",
    "num_classes = 2\n",
    "channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from math import ceil\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "def LoadImageandLabel(batch_size,AllVideoImageFolder,AllLabelFile):\n",
    "    #print(Originalpath)\n",
    "    count=0\n",
    "    \n",
    "    while True:\n",
    "        LabelFileindex = 0\n",
    "        for Originalpath in AllVideoImageFolder:\n",
    "\n",
    "            labelPath = AllLabelFile[LabelFileindex]\n",
    "            LabelFileindex = LabelFileindex + 1\n",
    "\n",
    "            Face_ImageDataList = []\n",
    "            Eyes_ImageDataList = []\n",
    "            Mouth_ImageDataList = []\n",
    "            #=====load all label in a video\n",
    "            LabelList = []\n",
    "            TempLabelList = []\n",
    "            inputfile = open(labelPath, 'r').read()\n",
    "            TempLabelList = list(map(int, inputfile))\n",
    "\n",
    "            #=========================\n",
    "\n",
    "            TEMP_ImageDataList = []\n",
    "\n",
    "            path = Originalpath+\"\\\\face\"\n",
    "\n",
    "\n",
    "            #=====find all files in path=======    \n",
    "            Facefiles = []\n",
    "            Eyefiles = []\n",
    "            Mouthfiles = []\n",
    "            # r=root, d=directories, f = files\n",
    "            for r, d, f in os.walk(path):\n",
    "                for file in f:\n",
    "                    if \".jpg\" in file:\n",
    "                        temp = os.path.join(r, file)\n",
    "                        \n",
    "                        Facefiles.append(temp)\n",
    "                        \n",
    "\n",
    "            Facefiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            #Mouthfiles=Mouthfiles[:-2]\n",
    "            #Eyefiles=Eyefiles[:-2]\n",
    "            Facefiles=Facefiles[:-2]\n",
    "            for FileIndex in range(len(Facefiles)):\n",
    "                #======================load label\n",
    "\n",
    "                index = Facefiles[FileIndex].find('frame')\n",
    "                framenumber =int(Facefiles[FileIndex][index+5:-4]) \n",
    "\n",
    "                #print(TempLabelList[framenumber-1])\n",
    "                Labelarray = to_categorical(TempLabelList[framenumber-1], num_classes=num_classes)\n",
    "                LabelList.append(Labelarray)\n",
    "                \n",
    "                #================================\n",
    "                ImgGray = cv2.imread(Facefiles[FileIndex],0)\n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                Face_ImageDataList.append(ImgGray)\n",
    "                 #====================================\n",
    "               \n",
    "                count = count +1\n",
    "                if count>=batch_size:\n",
    "                        #yield(np.array(Face_ImageDataList),np.array(LabelList))\n",
    "                        yield ([np.array(Face_ImageDataList)],np.array(LabelList))\n",
    "                        count=0\n",
    "                        Face_ImageDataList = []\n",
    "                        Eyes_ImageDataList = []\n",
    "                        Mouth_ImageDataList = []\n",
    "                        LabelList = []\n",
    "\n",
    "\n",
    "result= model.evaluate_generator(LoadImageandLabel(batch_size,AllImageFolder,AllLabelFile), steps=ceil(num_samples / batch_size),workers=5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.load(\".\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Training Image\\\\001\\\\night_noglasses\\\\sleepyCombination\\\\face\\\\frame3_Prob.npy\"))\n",
    "print(np.load(\".\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Training Image\\\\001\\\\night_noglasses\\\\sleepyCombination\\\\eyes\\\\frame3_Prob.npy\"))\n",
    "print(np.load(\".\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Training Image\\\\001\\\\night_noglasses\\\\sleepyCombination\\\\mouth\\\\frame3_Prob.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for multi label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.model_from_json(open('./MultiTask_Model_0821Second.json').read())\n",
    "model.load_weights('./MultiTask_Model_0821Second.h5')\n",
    "#model = tf.keras.models.model_from_json(open('.\\\\Temp\\\\backup\\\\MultiTask_Model_0821_9.json').read())\n",
    "#model.load_weights('.\\\\Temp\\\\backup\\\\MultiTask_Model_0821_9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 85, 66, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1conv2d (Conv2D)            (None, 42, 32, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1conv2dbn (BatchNormalizati (None, 42, 32, 32)   96          conv1conv2d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1conv2dact (Activation)     (None, 42, 32, 32)   0           conv1conv2dbn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2conv2d (Conv2D)            (None, 40, 30, 32)   9216        conv1conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2conv2dbn (BatchNormalizati (None, 40, 30, 32)   96          conv2conv2d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2conv2dact (Activation)     (None, 40, 30, 32)   0           conv2conv2dbn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3conv2d (Conv2D)            (None, 38, 28, 64)   18432       conv2conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3conv2dbn (BatchNormalizati (None, 38, 28, 64)   192         conv3conv2d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3conv2dact (Activation)     (None, 38, 28, 64)   0           conv3conv2dbn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_12conv2d (Conv2D)       (None, 36, 26, 96)   55296       conv3conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_12conv2dbn (BatchNormal (None, 36, 26, 96)   288         stem_br_12conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_11_maxpool_1 (MaxPoolin (None, 36, 26, 64)   0           conv3conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_12conv2dact (Activation (None, 36, 26, 96)   0           stem_br_12conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stem_concat_1 (Concatenate)     (None, 36, 26, 160)  0           stem_br_11_maxpool_1[0][0]       \n",
      "                                                                 stem_br_12conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_211conv2d (Conv2D)      (None, 36, 26, 64)   10240       stem_concat_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_211conv2dbn (BatchNorma (None, 36, 26, 64)   192         stem_br_211conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_211conv2dact (Activatio (None, 36, 26, 64)   0           stem_br_211conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_212conv2d (Conv2D)      (None, 36, 26, 64)   28672       stem_br_211conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_212conv2dbn (BatchNorma (None, 36, 26, 64)   192         stem_br_212conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_212conv2dact (Activatio (None, 36, 26, 64)   0           stem_br_212conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_213conv2d (Conv2D)      (None, 36, 26, 64)   28672       stem_br_212conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_221conv2d (Conv2D)      (None, 36, 26, 64)   10240       stem_concat_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_213conv2dbn (BatchNorma (None, 36, 26, 64)   192         stem_br_213conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_221conv2dbn (BatchNorma (None, 36, 26, 64)   192         stem_br_221conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_213conv2dact (Activatio (None, 36, 26, 64)   0           stem_br_213conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_221conv2dact (Activatio (None, 36, 26, 64)   0           stem_br_221conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_214conv2d (Conv2D)      (None, 34, 24, 96)   55296       stem_br_213conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_222conv2d (Conv2D)      (None, 34, 24, 96)   55296       stem_br_221conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_214conv2dbn (BatchNorma (None, 34, 24, 96)   288         stem_br_214conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_222conv2dbn (BatchNorma (None, 34, 24, 96)   288         stem_br_222conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_214conv2dact (Activatio (None, 34, 24, 96)   0           stem_br_214conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_222conv2dact (Activatio (None, 34, 24, 96)   0           stem_br_222conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_concat_2 (Concatenate)     (None, 34, 24, 192)  0           stem_br_214conv2dact[0][0]       \n",
      "                                                                 stem_br_222conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_31conv2d (Conv2D)       (None, 32, 22, 192)  331776      stem_concat_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_31conv2dbn (BatchNormal (None, 32, 22, 192)  576         stem_br_31conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_31conv2dact (Activation (None, 32, 22, 192)  0           stem_br_31conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_32_maxpool_2 (MaxPoolin (None, 32, 22, 192)  0           stem_concat_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_concat_3 (Concatenate)     (None, 32, 22, 384)  0           stem_br_31conv2dact[0][0]        \n",
      "                                                                 stem_br_32_maxpool_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_1conv2d (Conv2D)    (None, 32, 22, 32)   12288       stem_concat_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_1conv2dbn (BatchNor (None, 32, 22, 32)   96          incresA_1b2_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_1conv2dact (Activat (None, 32, 22, 32)   0           incresA_1b2_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_1conv2d (Conv2D)    (None, 32, 22, 32)   12288       stem_concat_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_2conv2d (Conv2D)    (None, 32, 22, 48)   13824       incresA_1b2_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_1conv2dbn (BatchNor (None, 32, 22, 32)   96          incresA_1b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_2conv2dbn (BatchNor (None, 32, 22, 48)   144         incresA_1b2_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_1conv2dact (Activat (None, 32, 22, 32)   0           incresA_1b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_2conv2dact (Activat (None, 32, 22, 48)   0           incresA_1b2_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b0conv2d (Conv2D)      (None, 32, 22, 32)   12288       stem_concat_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_2conv2d (Conv2D)    (None, 32, 22, 32)   9216        incresA_1b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_3conv2d (Conv2D)    (None, 32, 22, 64)   27648       incresA_1b2_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b0conv2dbn (BatchNorma (None, 32, 22, 32)   96          incresA_1b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_2conv2dbn (BatchNor (None, 32, 22, 32)   96          incresA_1b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_3conv2dbn (BatchNor (None, 32, 22, 64)   192         incresA_1b2_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b0conv2dact (Activatio (None, 32, 22, 32)   0           incresA_1b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_2conv2dact (Activat (None, 32, 22, 32)   0           incresA_1b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_3conv2dact (Activat (None, 32, 22, 64)   0           incresA_1b2_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1_concat (Concatenate)  (None, 32, 22, 128)  0           incresA_1b0conv2dact[0][0]       \n",
      "                                                                 incresA_1b1_2conv2dact[0][0]     \n",
      "                                                                 incresA_1b2_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1filt_exp_1x1conv2d (Co (None, 32, 22, 384)  49152       incresA_1_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1filt_exp_1x1conv2dbn ( (None, 32, 22, 384)  1152        incresA_1filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresA_1act_scaling (Lambda)   (None, 32, 22, 384)  0           stem_concat_3[0][0]              \n",
      "                                                                 incresA_1filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_1conv2d (Conv2D)    (None, 32, 22, 32)   12288       incresA_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_1conv2dbn (BatchNor (None, 32, 22, 32)   96          incresA_2b2_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_1conv2dact (Activat (None, 32, 22, 32)   0           incresA_2b2_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_1conv2d (Conv2D)    (None, 32, 22, 32)   12288       incresA_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_2conv2d (Conv2D)    (None, 32, 22, 48)   13824       incresA_2b2_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_1conv2dbn (BatchNor (None, 32, 22, 32)   96          incresA_2b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_2conv2dbn (BatchNor (None, 32, 22, 48)   144         incresA_2b2_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_1conv2dact (Activat (None, 32, 22, 32)   0           incresA_2b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_2conv2dact (Activat (None, 32, 22, 48)   0           incresA_2b2_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b0conv2d (Conv2D)      (None, 32, 22, 32)   12288       incresA_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_2conv2d (Conv2D)    (None, 32, 22, 32)   9216        incresA_2b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_3conv2d (Conv2D)    (None, 32, 22, 64)   27648       incresA_2b2_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b0conv2dbn (BatchNorma (None, 32, 22, 32)   96          incresA_2b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_2conv2dbn (BatchNor (None, 32, 22, 32)   96          incresA_2b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_3conv2dbn (BatchNor (None, 32, 22, 64)   192         incresA_2b2_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b0conv2dact (Activatio (None, 32, 22, 32)   0           incresA_2b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_2conv2dact (Activat (None, 32, 22, 32)   0           incresA_2b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_3conv2dact (Activat (None, 32, 22, 64)   0           incresA_2b2_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2_concat (Concatenate)  (None, 32, 22, 128)  0           incresA_2b0conv2dact[0][0]       \n",
      "                                                                 incresA_2b1_2conv2dact[0][0]     \n",
      "                                                                 incresA_2b2_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2filt_exp_1x1conv2d (Co (None, 32, 22, 384)  49152       incresA_2_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2filt_exp_1x1conv2dbn ( (None, 32, 22, 384)  1152        incresA_2filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresA_2act_scaling (Lambda)   (None, 32, 22, 384)  0           incresA_1act_scaling[0][0]       \n",
      "                                                                 incresA_2filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_1conv2d (Conv2D)      (None, 32, 22, 256)  98304       incresA_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_1conv2dbn (BatchNorma (None, 32, 22, 256)  768         x_red1_c2_1conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_1conv2dact (Activatio (None, 32, 22, 256)  0           x_red1_c2_1conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_2conv2d (Conv2D)      (None, 32, 22, 256)  589824      x_red1_c2_1conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_2conv2dbn (BatchNorma (None, 32, 22, 256)  768         x_red1_c2_2conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_2conv2dact (Activatio (None, 32, 22, 256)  0           x_red1_c2_2conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c1conv2d (Conv2D)        (None, 15, 10, 384)  1327104     incresA_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_3conv2d (Conv2D)      (None, 15, 10, 384)  884736      x_red1_c2_2conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c1conv2dbn (BatchNormali (None, 15, 10, 384)  1152        x_red1_c1conv2d[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_3conv2dbn (BatchNorma (None, 15, 10, 384)  1152        x_red1_c2_3conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "red_maxpool_1 (MaxPooling2D)    (None, 15, 10, 384)  0           incresA_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c1conv2dact (Activation) (None, 15, 10, 384)  0           x_red1_c1conv2dbn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_3conv2dact (Activatio (None, 15, 10, 384)  0           x_red1_c2_3conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "red_concat_1 (Concatenate)      (None, 15, 10, 1152) 0           red_maxpool_1[0][0]              \n",
      "                                                                 x_red1_c1conv2dact[0][0]         \n",
      "                                                                 x_red1_c2_3conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_1conv2d (Conv2D)    (None, 15, 10, 128)  147456      red_concat_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_1conv2dbn (BatchNor (None, 15, 10, 128)  384         incresB_1b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_1conv2dact (Activat (None, 15, 10, 128)  0           incresB_1b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_2conv2d (Conv2D)    (None, 15, 10, 160)  143360      incresB_1b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_2conv2dbn (BatchNor (None, 15, 10, 160)  480         incresB_1b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_2conv2dact (Activat (None, 15, 10, 160)  0           incresB_1b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b0conv2d (Conv2D)      (None, 15, 10, 192)  221184      red_concat_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_3conv2d (Conv2D)    (None, 15, 10, 192)  215040      incresB_1b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b0conv2dbn (BatchNorma (None, 15, 10, 192)  576         incresB_1b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_3conv2dbn (BatchNor (None, 15, 10, 192)  576         incresB_1b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b0conv2dact (Activatio (None, 15, 10, 192)  0           incresB_1b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_3conv2dact (Activat (None, 15, 10, 192)  0           incresB_1b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1_mixed (Concatenate)   (None, 15, 10, 384)  0           incresB_1b0conv2dact[0][0]       \n",
      "                                                                 incresB_1b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1filt_exp_1x1conv2d (Co (None, 15, 10, 1152) 442368      incresB_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1filt_exp_1x1conv2dbn ( (None, 15, 10, 1152) 3456        incresB_1filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresB_1act_scaling (Lambda)   (None, 15, 10, 1152) 0           red_concat_1[0][0]               \n",
      "                                                                 incresB_1filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_1conv2d (Conv2D)    (None, 15, 10, 128)  147456      incresB_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_1conv2dbn (BatchNor (None, 15, 10, 128)  384         incresB_2b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_1conv2dact (Activat (None, 15, 10, 128)  0           incresB_2b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_2conv2d (Conv2D)    (None, 15, 10, 160)  143360      incresB_2b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_2conv2dbn (BatchNor (None, 15, 10, 160)  480         incresB_2b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_2conv2dact (Activat (None, 15, 10, 160)  0           incresB_2b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b0conv2d (Conv2D)      (None, 15, 10, 192)  221184      incresB_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_3conv2d (Conv2D)    (None, 15, 10, 192)  215040      incresB_2b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b0conv2dbn (BatchNorma (None, 15, 10, 192)  576         incresB_2b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_3conv2dbn (BatchNor (None, 15, 10, 192)  576         incresB_2b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b0conv2dact (Activatio (None, 15, 10, 192)  0           incresB_2b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_3conv2dact (Activat (None, 15, 10, 192)  0           incresB_2b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2_mixed (Concatenate)   (None, 15, 10, 384)  0           incresB_2b0conv2dact[0][0]       \n",
      "                                                                 incresB_2b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2filt_exp_1x1conv2d (Co (None, 15, 10, 1152) 442368      incresB_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2filt_exp_1x1conv2dbn ( (None, 15, 10, 1152) 3456        incresB_2filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresB_2act_scaling (Lambda)   (None, 15, 10, 1152) 0           incresB_1act_scaling[0][0]       \n",
      "                                                                 incresB_2filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c31conv2d (Conv2D)       (None, 15, 10, 256)  294912      incresB_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c31conv2dbn (BatchNormal (None, 15, 10, 256)  768         x_red2_c31conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c31conv2dact (Activation (None, 15, 10, 256)  0           x_red2_c31conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c11conv2d (Conv2D)       (None, 15, 10, 256)  294912      incresB_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c21conv2d (Conv2D)       (None, 15, 10, 256)  294912      incresB_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c32conv2d (Conv2D)       (None, 15, 10, 256)  589824      x_red2_c31conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c11conv2dbn (BatchNormal (None, 15, 10, 256)  768         x_red2_c11conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c21conv2dbn (BatchNormal (None, 15, 10, 256)  768         x_red2_c21conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c32conv2dbn (BatchNormal (None, 15, 10, 256)  768         x_red2_c32conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c11conv2dact (Activation (None, 15, 10, 256)  0           x_red2_c11conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c21conv2dact (Activation (None, 15, 10, 256)  0           x_red2_c21conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c32conv2dact (Activation (None, 15, 10, 256)  0           x_red2_c32conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c12conv2d (Conv2D)       (None, 7, 4, 384)    884736      x_red2_c11conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c22conv2d (Conv2D)       (None, 7, 4, 256)    589824      x_red2_c21conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c33conv2d (Conv2D)       (None, 7, 4, 256)    589824      x_red2_c32conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c12conv2dbn (BatchNormal (None, 7, 4, 384)    1152        x_red2_c12conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c22conv2dbn (BatchNormal (None, 7, 4, 256)    768         x_red2_c22conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c33conv2dbn (BatchNormal (None, 7, 4, 256)    768         x_red2_c33conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "red_maxpool_2 (MaxPooling2D)    (None, 7, 4, 1152)   0           incresB_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c12conv2dact (Activation (None, 7, 4, 384)    0           x_red2_c12conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c22conv2dact (Activation (None, 7, 4, 256)    0           x_red2_c22conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c33conv2dact (Activation (None, 7, 4, 256)    0           x_red2_c33conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "red_concat_2 (Concatenate)      (None, 7, 4, 2048)   0           red_maxpool_2[0][0]              \n",
      "                                                                 x_red2_c12conv2dact[0][0]        \n",
      "                                                                 x_red2_c22conv2dact[0][0]        \n",
      "                                                                 x_red2_c33conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_1conv2d (Conv2D)    (None, 7, 4, 192)    393216      red_concat_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_1conv2dbn (BatchNor (None, 7, 4, 192)    576         incresC_1b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_1conv2dact (Activat (None, 7, 4, 192)    0           incresC_1b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_2conv2d (Conv2D)    (None, 7, 4, 224)    129024      incresC_1b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_2conv2dbn (BatchNor (None, 7, 4, 224)    672         incresC_1b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_2conv2dact (Activat (None, 7, 4, 224)    0           incresC_1b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b0conv2d (Conv2D)      (None, 7, 4, 192)    393216      red_concat_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_3conv2d (Conv2D)    (None, 7, 4, 256)    172032      incresC_1b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b0conv2dbn (BatchNorma (None, 7, 4, 192)    576         incresC_1b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_3conv2dbn (BatchNor (None, 7, 4, 256)    768         incresC_1b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b0conv2dact (Activatio (None, 7, 4, 192)    0           incresC_1b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_3conv2dact (Activat (None, 7, 4, 256)    0           incresC_1b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1_mixed (Concatenate)   (None, 7, 4, 448)    0           incresC_1b0conv2dact[0][0]       \n",
      "                                                                 incresC_1b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1fin1x1conv2d (Conv2D)  (None, 7, 4, 2048)   917504      incresC_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1fin1x1conv2dbn (BatchN (None, 7, 4, 2048)   6144        incresC_1fin1x1conv2d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1act_saling (Lambda)    (None, 7, 4, 2048)   0           red_concat_2[0][0]               \n",
      "                                                                 incresC_1fin1x1conv2dbn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_1conv2d (Conv2D)    (None, 7, 4, 192)    393216      incresC_1act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_1conv2dbn (BatchNor (None, 7, 4, 192)    576         incresC_2b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_1conv2dact (Activat (None, 7, 4, 192)    0           incresC_2b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_2conv2d (Conv2D)    (None, 7, 4, 224)    129024      incresC_2b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_2conv2dbn (BatchNor (None, 7, 4, 224)    672         incresC_2b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_2conv2dact (Activat (None, 7, 4, 224)    0           incresC_2b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b0conv2d (Conv2D)      (None, 7, 4, 192)    393216      incresC_1act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_3conv2d (Conv2D)    (None, 7, 4, 256)    172032      incresC_2b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b0conv2dbn (BatchNorma (None, 7, 4, 192)    576         incresC_2b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_3conv2dbn (BatchNor (None, 7, 4, 256)    768         incresC_2b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b0conv2dact (Activatio (None, 7, 4, 192)    0           incresC_2b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_3conv2dact (Activat (None, 7, 4, 256)    0           incresC_2b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2_mixed (Concatenate)   (None, 7, 4, 448)    0           incresC_2b0conv2dact[0][0]       \n",
      "                                                                 incresC_2b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2fin1x1conv2d (Conv2D)  (None, 7, 4, 2048)   917504      incresC_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2fin1x1conv2dbn (BatchN (None, 7, 4, 2048)   6144        incresC_2fin1x1conv2d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2act_saling (Lambda)    (None, 7, 4, 2048)   0           incresC_1act_saling[0][0]        \n",
      "                                                                 incresC_2fin1x1conv2dbn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           incresC_2act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         6144        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2048)         6144        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2048)         6144        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1049088     batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2048)         6144        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          1049088     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          1536        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512)          1536        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          1049088     batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512)          1536        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           32832       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           32832       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          1536        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           32832       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           32832       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 192)          0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 192)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Head (Dense)                    (None, 3)            195         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Mouth (Dense)                   (None, 3)            195         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Eyes (Dense)                    (None, 2)            130         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Total (Dense)                   (None, 2)            386         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 18,068,202\n",
      "Trainable params: 18,018,154\n",
      "Non-trainable params: 50,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def FindFile(path,keyword):\n",
    "\n",
    "    #path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "    #path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset'\n",
    "\n",
    "    File = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if (keyword in file) and (\"_night_noglasses_mixing_\" in file ):\n",
    "                File.append(os.path.join(r, file))\n",
    "\n",
    "    #for f in File:\n",
    "    #    print(f)\n",
    "    print(np.array(File).shape)\n",
    "    \n",
    "    return File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Evaluation Dataset\\\\004\\\\004_night_noglasses_mixing_drowsiness.txt',\n",
       " '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Evaluation Dataset\\\\022\\\\022_night_noglasses_mixing_drowsiness.txt',\n",
       " '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Evaluation Dataset\\\\026\\\\026_night_noglasses_mixing_drowsiness.txt',\n",
       " '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Evaluation Dataset\\\\030\\\\030_night_noglasses_mixing_drowsiness.txt']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Head_Testing_AllLabelFile = FindFile('.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset','head.txt')\n",
    "Eye_Testing_AllLabelFile = FindFile('.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset','eye.txt')\n",
    "Mouth_Testing_AllLabelFile = FindFile('.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset','mouth.txt')\n",
    "Total_Testing_AllLabelFile = FindFile('.\\Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset','drowsiness.txt')\n",
    "Total_Testing_AllLabelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Dataset\\Training_Evaluation_Dataset\\Testing Image\\004\\004_nightnoglasses_mix\n",
      ".\\Dataset\\Training_Evaluation_Dataset\\Testing Image\\022\\022_nightnoglasses_mix\n",
      ".\\Dataset\\Training_Evaluation_Dataset\\Testing Image\\026\\026_nightnoglasses_mix\n",
      ".\\Dataset\\Training_Evaluation_Dataset\\Testing Image\\030\\030_nightnoglasses_mix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#path = '.\\Dataset\\Training_Evaluation_Dataset\\Training Dataset\\\\'\n",
    "path = '.\\Dataset\\Training_Evaluation_Dataset\\Testing Image'\n",
    "\n",
    "AllImageFolderTesting = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for directory in d:\n",
    "        if (\"mix\" in directory) and (\"nightnoglasses\" in directory ):\n",
    "            #print(directory)\n",
    "            AllImageFolderTesting.append(os.path.join(r, directory))\n",
    "        \n",
    "for d in AllImageFolderTesting:\n",
    "    print(d)\n",
    "np.array(AllImageFolderTesting).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sample = 167168\n",
    "testing_sample = 9569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from math import ceil\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def LoadImageandLabel(Flag,batch_size,AllVideoImageFolder,Head_AllLabelFile,Mouth_AllLabelFile,Eye_AllLabelFile,Total_AllLabelFile):\n",
    "    #print(Originalpath)\n",
    "    count=0\n",
    "    \n",
    "    while True:\n",
    "        LabelFileindex = 0\n",
    "        \n",
    "\n",
    "        Face_ImageDataList = []\n",
    "        \n",
    "        TotalLabelList = []\n",
    "        HeadLabelList = []\n",
    "        EyeLabelList = []\n",
    "        MouthLabelList = []\n",
    "        totalcount = 0\n",
    "        for Originalpath in AllVideoImageFolder:\n",
    "            #print(Originalpath)\n",
    "            #=====load all label in a video\n",
    "            HeadlabelPath = Head_AllLabelFile[LabelFileindex]\n",
    "            MouthlabelPath = Mouth_AllLabelFile[LabelFileindex]\n",
    "            EyelabelPath = Eye_AllLabelFile[LabelFileindex]\n",
    "            TotallabelPath = Total_AllLabelFile[LabelFileindex]\n",
    "            \n",
    "            LabelFileindex = LabelFileindex + 1\n",
    "            \n",
    "                \n",
    "            inputfile = open(HeadlabelPath, 'r').read()\n",
    "            HeadTempLabelList = list(map(int, inputfile))\n",
    "            inputfile = open(MouthlabelPath, 'r').read()\n",
    "            MouthTempLabelList = list(map(int, inputfile))\n",
    "            inputfile = open(EyelabelPath, 'r').read()\n",
    "            EyeTempLabelList = list(map(int, inputfile))\n",
    "            inputfile = open(TotallabelPath, 'r').read()\n",
    "            TotalTempLabelList = list(map(int, inputfile))\n",
    "\n",
    "            #=====find all files in path=======\n",
    "            path = Originalpath+\"\\\\face\"\n",
    "            Facefiles = []\n",
    "            # r=root, d=directories, f = files\n",
    "            for r, d, f in os.walk(path):\n",
    "                for file in f:\n",
    "                    if \".jpg\" and 'frame_Middle'in file and (not \"ALL\" in file):\n",
    "                        temp = os.path.join(r, file)\n",
    "                        Facefiles.append(temp)\n",
    "            \n",
    "            Facefiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            Facefiles=Facefiles[:-2]\n",
    "            \n",
    "            #print(Originalpath)\n",
    "            #print(len(TempLabelList))\n",
    "            \n",
    "            for FileIndex in range(len(Facefiles)):\n",
    "                #======================load label\n",
    "                \n",
    "                index = Facefiles[FileIndex].find('frame_Middle')\n",
    "                \n",
    "                framenumber =int(Facefiles[FileIndex][index+12:-4]) \n",
    "                                \n",
    "                HeadLabelarray = to_categorical(HeadTempLabelList[framenumber-1], num_classes=3)\n",
    "                HeadLabelList.append(HeadLabelarray)\n",
    "                \n",
    "                MouthLabelarray = to_categorical(MouthTempLabelList[framenumber-1], num_classes=3)\n",
    "                MouthLabelList.append(MouthLabelarray)\n",
    "                \n",
    "                EyeLabelarray = to_categorical(EyeTempLabelList[framenumber-1], num_classes=2)\n",
    "                EyeLabelList.append(EyeLabelarray)\n",
    "\n",
    "                TotalLabelarray = to_categorical(TotalTempLabelList[framenumber-1], num_classes=2)\n",
    "                TotalLabelList.append(TotalLabelarray)\n",
    "\n",
    "                #================================\n",
    "                ImgGray = cv2.imread(Facefiles[FileIndex],0)\n",
    "                \n",
    "                #data augmentation\n",
    "                if((random.uniform(0, 1)>0.5) and Flag == 0):\n",
    "                    ImgGray = cv2.flip(ImgGray,1)\n",
    "                    \n",
    "                ImgGray = ImgGray.reshape(ImgGray.shape[0],ImgGray.shape[1],1)\n",
    "                \n",
    "\n",
    "                    \n",
    "                Face_ImageDataList.append(ImgGray)\n",
    "               \n",
    "                count = count +1\n",
    "                totalcount = totalcount+1\n",
    "                if count>=batch_size:\n",
    "                    \n",
    "                        yield ([np.array(Face_ImageDataList)],\n",
    "                                                               [np.array(HeadLabelList),\n",
    "                                                               np.array(MouthLabelList),\n",
    "                                                               np.array(EyeLabelList), \n",
    "                                                               np.array(TotalLabelList)\n",
    "                                                               ]\n",
    "                                                               )\n",
    "                        count=0\n",
    "                        Face_ImageDataList = []\n",
    "                        HeadLabelList = []\n",
    "                        EyeLabelList = []\n",
    "                        MouthLabelList = []\n",
    "                        TotalLabelList = []\n",
    "                        \n",
    "        print(totalcount)\n",
    "        #return Face_ImageDataList,HeadLabelList,MouthLabelList,EyeLabelList\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/113 [=>............................] - ETA: 2:599569\n",
      " 28/113 [======>.......................] - ETA: 1:019569\n",
      " 47/113 [===========>..................] - ETA: 34s9569\n",
      " 66/113 [================>.............] - ETA: 20s9569\n",
      " 85/113 [=====================>........] - ETA: 11s9569\n",
      "104/113 [==========================>...] - ETA: 3s9569\n",
      "113/113 [==============================] - 41s 359ms/step\n"
     ]
    }
   ],
   "source": [
    "testing_sample = 56123\n",
    "import tensorflow as tf\n",
    "\n",
    "#model = tf.keras.models.model_from_json(open('./MultiTask_Model_0821Second.json').read())\n",
    "#model.load_weights('./MultiTask_Model_0821Second.h5')\n",
    "model = tf.keras.models.model_from_json(open('.\\\\Temp\\\\backup\\\\MultiTask_Model_11.json').read())\n",
    "model.load_weights('.\\\\Temp\\\\backup\\\\MultiTask_Model_11.h5')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "result= model.evaluate_generator(LoadImageandLabel(1,500,AllImageFolderTesting,Head_Testing_AllLabelFile,Mouth_Testing_AllLabelFile\n",
    "                                          ,Eye_Testing_AllLabelFile,Total_Testing_AllLabelFile), steps=ceil(testing_sample / 500),workers=5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.2630833833069106,\n",
       " 0.2510061141556532,\n",
       " 0.3238416961399372,\n",
       " 1.2988374265930882,\n",
       " 1.3893981422067365,\n",
       " 0.9105562250199142,\n",
       " 0.8745274987360897,\n",
       " 0.46656449920082504,\n",
       " 0.4709997270217157]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model tensorflow 1.X \n",
    "# Kneron Tool Chain\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "with open('./Temp/backup/MultiTask_Model_11.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights('./Temp/backup/MultiTask_Model_11.h5')\n",
    "\n",
    "\n",
    "model.save('./MultiTask_Model_11_2.h5')\n",
    "\n",
    "# check GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fac2d9b360ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#MultiTask_Model_0821_9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Temp/backup/MultiTask_Model_11.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Temp/backup/MultiTask_Model_11.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# loading model\n",
    "from tensorflow.keras import Model\n",
    "#MultiTask_Model_0821_9\n",
    "model = tf.keras.models.model_from_json(open('./Temp/backup/MultiTask_Model_11.json').read())\n",
    "model.load_weights('./Temp/backup/MultiTask_Model_11.h5')\n",
    "\n",
    "model.save('./MultiTask_Model_11_2.h5')\n",
    "\n",
    "# check GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawtext(image,Head,Mouth,Eyes,Total):\n",
    "    \n",
    "    if(Head == 0):\n",
    "        cv2.putText(image,\"Head: Stillness\", (400 ,300),font,0.5,color)\n",
    "    elif(Head == 1):\n",
    "        cv2.putText(image,\"Head: Nodding\", (400 ,300),font,0.5,color)\n",
    "    else:\n",
    "        cv2.putText(image,\"Head: Looking aside\", (400 ,300),font,0.5,color)\n",
    "    \n",
    "    if(Mouth == 0):\n",
    "        cv2.putText(image,\"Mouth: Stillness\", (400 ,320),font,0.5,color)\n",
    "    elif(Mouth == 1):\n",
    "        cv2.putText(image,\"Mouth: Yawning\", (400 ,320),font,0.5,color)\n",
    "    else:\n",
    "        cv2.putText(image,\"Mouth: Talking & Laughing\", (400 ,320),font,0.5,color)\n",
    "        \n",
    "    if(Eyes == 0):\n",
    "        cv2.putText(image,\"Eyes: Stillness\", (400 ,340),font,0.5,color)\n",
    "    else:\n",
    "        cv2.putText(image,\"Eyes: Sleepy-eyes\", (400 ,340),font,0.5,color)\n",
    "    #cv2.putText(image,\"Eyes:\"+str(Eyes), (500 ,340),font,0.5,color)\n",
    "    \n",
    "    if(Total == 0):\n",
    "        cv2.putText(image,\"Total: Stillness\", (400 ,360),font,0.5,color)\n",
    "    else:\n",
    "        cv2.putText(image,\"Total: Drowsy\", (400 ,360),font,0.5,color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raoblack/Documents/NTHU_dataset/Training_Evaluation_Dataset/Training Dataset/023/noglasses/nonsleepyCombination.avi\n",
      "2847\n"
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "\n",
    "eyes_width = 60\n",
    "eyes_height = 33\n",
    "mouth_width = 50\n",
    "mouth_height = 33\n",
    "face_width = 66\n",
    "face_height = 85\n",
    "num_classes = 2\n",
    "channel = 1\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "color = (0, 255, 255)\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "    \n",
    "    \n",
    "#filename = '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Evaluation Dataset\\\\022\\\\022_noglasses_mix.mp4'\n",
    "filename = '/home/raoblack/Documents/NTHU_dataset/Training_Evaluation_Dataset/Training Dataset/023/noglasses/nonsleepyCombination.avi'\n",
    "#filename = '.\\\\Dataset\\\\Training_Evaluation_Dataset\\\\Training Dataset\\\\005\\\\noglasses\\\\nonsleepyCombination.avi'\n",
    "print(filename)\n",
    "cap = cv2.VideoCapture(filename)\n",
    "Face_ImageDataList = []\n",
    "\n",
    "missing_frame = 0\n",
    "DropList = []\n",
    "\n",
    "eyes_w = eyes_width\n",
    "eyes_h = eyes_height\n",
    "face_w = face_width\n",
    "face_h = face_height\n",
    "mouth_w = mouth_width\n",
    "mouth_h = mouth_height\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(length)\n",
    "x,y,w,h = 0,0,0,0\n",
    "frame = -1\n",
    "Head, Mouth, Eyes, Total = 0, 0, 0, 0\n",
    "\n",
    "cv2.namedWindow('frame', cv2.WINDOW_AUTOSIZE)\n",
    "def ChangeFrame(value):\n",
    "    cap.set(1,cv2.getTrackbarPos('Frame','frame'));\n",
    "\n",
    "frame_lenth = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "\n",
    "cv2.createTrackbar('Frame','frame',0,frame_lenth,ChangeFrame)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # load the input image and convert it to grayscale\n",
    "    ret, image = cap.read()\n",
    "    frame = frame + 1\n",
    "    if (not ret):\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    height,width = image.shape[:2]\n",
    "    faces = detector.detect_faces(image)\n",
    "\n",
    "    if(np.array(faces).shape[0] > 0):\n",
    "        face = faces[0]\n",
    "        x,y,w,h = face['box']\n",
    "\n",
    "        face_image = image[max(0,y):max(0,y+h),max(0,x):max(0,x+w)]\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        face_image1 = cv2.resize(face_image,(face_w,face_h),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        face_image1 = cv2.cvtColor(face_image1, cv2.COLOR_BGR2GRAY)\n",
    "        #print(face_image1.shape)\n",
    "        Model_input = face_image1.reshape(1,face_image1.shape[0],face_image1.shape[1],1)\n",
    "        Prob = model.predict(Model_input)\n",
    "        \n",
    "        Head = Prob[0].argmax(axis=-1)\n",
    "        Mouth = Prob[1].argmax(axis=-1)\n",
    "        Eyes = Prob[2].argmax(axis=-1)\n",
    "        #print(np.amax(Prob[3]))\n",
    "        \n",
    "        if(np.amax(Prob[3])>0.6):\n",
    "            Total = Prob[3].argmax(axis=-1)\n",
    "        \n",
    "        #print(Head, end = ', ')\n",
    "        #print(Mouth, end = ', ')\n",
    "        #print(Eyes, end = ', ')\n",
    "        #print(Total)\n",
    "        image = drawtext(image,Head,Mouth,Eyes,Total)\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif (missing_frame<60 and (not((x == 0) or (y == 0) or (w == 0) or (h == 0) ))):\n",
    "        print ('missing using last frame') \n",
    "        missing_frame = missing_frame + 1        \n",
    "\n",
    "        face_image = image[max(0,y):max(0,y+h),max(0,x):max(0,x+w)]\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        face_image1 = cv2.resize(face_image,(face_w,face_h),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        face_image1 = cv2.cvtColor(face_image1, cv2.COLOR_BGR2GRAY)\n",
    "        #print(face_image1.shape)\n",
    "        Model_input = face_image1.reshape(1,face_image1.shape[0],face_image1.shape[1],1)\n",
    "        Prob = model.predict(Model_input)\n",
    "        \n",
    "        \n",
    "        Head = Prob[0].argmax(axis=-1)\n",
    "        Mouth = Prob[1].argmax(axis=-1)\n",
    "        Eyes = Prob[2].argmax(axis=-1)\n",
    "        #print(np.amax(Prob[3]))\n",
    "        \n",
    "        if(np.amax(Prob[3])>0.6):\n",
    "            Total = Prob[3].argmax(axis=-1)\n",
    "        \n",
    "        #print(Head, end = ', ')\n",
    "        #print(Mouth, end = ', ')\n",
    "        #print(Eyes, end = ', ')\n",
    "        #print(Total)\n",
    "        image = drawtext(image,Head,Mouth,Eyes,Total)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "\n",
    "    cv2.putText(image, \"FPS:\" + str(round(1.0 / (time.time() - start_time))), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, (76, 0, 153), 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('frame',image)\n",
    "\n",
    "    # print(\"FPS: \", 1.0 / (time.time() - start_time))\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
